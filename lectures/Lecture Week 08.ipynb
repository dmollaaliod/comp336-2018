{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Streams\n",
    "The following code illustrates how we can use hashes to test membership in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_hash(item, nbuckets):\n",
    "    \"Return a hash value between 0 and nbuckets - 1\"\n",
    "    return hash(item) % nbuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "951"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash(\"Peter\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash(\"Mary\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash('Susan', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash('John', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the filter\n",
    "NBUCKETS = 1000\n",
    "S = ['John', 'Mary', 'Peter', 'Susan']\n",
    "hash_filter = np.zeros(NBUCKETS, dtype=np.bool)\n",
    "for s in S:\n",
    "    hash_filter[my_hash(s, NBUCKETS)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the filter\n",
    "def in_filter(item):\n",
    "    \"Return True if the item is in the filter\"\n",
    "    return hash_filter[my_hash(item, NBUCKETS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_filter(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_filter(\"Diego\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom Filter\n",
    "The following code implements a Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash((\"John\", 0), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hash((\"John\", 1), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the filter\n",
    "K = 5 # We use 5 independent hash functions\n",
    "NBUCKETS = 1000\n",
    "S = ['John', 'Mary', 'Peter', 'Susan']\n",
    "hash_filter = np.zeros(NBUCKETS, dtype=np.bool)\n",
    "for s in S:\n",
    "    for k in range(K):\n",
    "        hash_filter[my_hash((s, k), NBUCKETS)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the filter\n",
    "def in_filter(item):\n",
    "    \"Return True if the item is in the filter\"\n",
    "    result = True\n",
    "    for k in range(K):\n",
    "        result = result and hash_filter[my_hash((item, k), NBUCKETS)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_filter('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_filter('Diego')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Flajolet-Martin Algorithm\n",
    "The following algorithm estimates the count of distinct items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBUCKETS = 2**32\n",
    "def tail_length(item):\n",
    "    \"Return the tail length of the hash of the item\"\n",
    "    s = bin(hash(item) % NBUCKETS)\n",
    "    return len(s) - len(s.rstrip('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b10011011001001010001101000000110\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(bin(hash(\"Phillip\") % NBUCKETS))\n",
    "print(tail_length(\"Phillip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4294967296"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_distinct(stream):\n",
    "    maxR = 0\n",
    "    for s in stream:\n",
    "        r = tail_length(s)\n",
    "        if r > maxR:\n",
    "            maxR = r\n",
    "    return 2**maxR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate the number of distinct words in the Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "words = nltk.corpus.brown.words()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_distinct(words[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with a brute force exact count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2690"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words[:10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variant using multiple hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "K = 256 # number of distinct hashes\n",
    "G = 16  # size of each group of hashes\n",
    "assert K % G == 0 # Check that K is divisible by G\n",
    "\n",
    "def count_distinct(stream):\n",
    "    maxR = np.zeros(K) # Initialise all R for all hashes to zero \n",
    "    \n",
    "    # 1. Compute R for each hash\n",
    "    print(\"Step 1\")\n",
    "    for s in stream:\n",
    "        for h in range(K):\n",
    "            r = tail_length((s, h))\n",
    "            if r > maxR[h]:\n",
    "                maxR[h] = r\n",
    "                \n",
    "    plt.hist(maxR)\n",
    "                \n",
    "    # 2. Combine all R\n",
    "    print(\"Step 2\")\n",
    "    Counts = []\n",
    "    for group in range(K//G):\n",
    "        groupCounts = []\n",
    "        for h in range(G):\n",
    "            groupCounts.append(2**maxR[group*G + h])\n",
    "        Counts.append(np.median(groupCounts))\n",
    "    return(np.mean(Counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Step 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2752.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/Rfoer6f1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4696e7400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_distinct(words[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3,4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([1,2,3,4,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## More Streams\n",
    "The following code shows some simple processing of streams by answering some of the questions from the lectures -- week 8, page 4. The queries are related to a stream of recordings from a temperature sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert when the temperature exceeds 25 degrees\n",
    "This is a very simple case that does not need to keep any working storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessStream:\n",
    "    def step(self, s):\n",
    "        if s >= 25:\n",
    "            print(\"Alert: Temperature is %f\" % s)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the stream at work with some simulated data. The data have been obtained from http://www.bom.gov.au/climate/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def temperature_sensor():\n",
    "    with open('temperature_sensor/IDCJAC0010_066062_1800_Data.csv') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for line in reader:\n",
    "            yield float(line['Maximum temperature (Degree C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert: Temperature is 25.100000\n",
      "Alert: Temperature is 33.900000\n",
      "Alert: Temperature is 27.200000\n",
      "Alert: Temperature is 28.600000\n",
      "Alert: Temperature is 27.300000\n",
      "Alert: Temperature is 25.400000\n",
      "Alert: Temperature is 33.100000\n",
      "Alert: Temperature is 36.900000\n",
      "Alert: Temperature is 25.800000\n",
      "Alert: Temperature is 26.900000\n",
      "Alert: Temperature is 25.600000\n",
      "Alert: Temperature is 25.900000\n",
      "Alert: Temperature is 25.600000\n",
      "Alert: Temperature is 25.000000\n",
      "Alert: Temperature is 26.900000\n",
      "Alert: Temperature is 27.200000\n",
      "Alert: Temperature is 35.600000\n",
      "Alert: Temperature is 32.300000\n",
      "Alert: Temperature is 26.800000\n",
      "Alert: Temperature is 26.200000\n",
      "Alert: Temperature is 32.800000\n",
      "Alert: Temperature is 28.600000\n",
      "Alert: Temperature is 25.400000\n",
      "Alert: Temperature is 26.500000\n",
      "Alert: Temperature is 25.900000\n",
      "Alert: Temperature is 25.000000\n",
      "Alert: Temperature is 26.700000\n",
      "Alert: Temperature is 25.000000\n",
      "Alert: Temperature is 28.200000\n",
      "Alert: Temperature is 25.300000\n",
      "Alert: Temperature is 25.000000\n",
      "Alert: Temperature is 26.000000\n",
      "Alert: Temperature is 30.300000\n",
      "Alert: Temperature is 25.700000\n",
      "Alert: Temperature is 26.900000\n",
      "Alert: Temperature is 30.400000\n",
      "Alert: Temperature is 28.000000\n",
      "Alert: Temperature is 31.100000\n",
      "Alert: Temperature is 26.200000\n",
      "Alert: Temperature is 26.400000\n"
     ]
    }
   ],
   "source": [
    "t = temperature_sensor()\n",
    "stream_processor = ProcessStream()\n",
    "for i in range(100):\n",
    "    stream_processor.step(next(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the 24 most recent readings\n",
    "The working storage will need to keep track of the 24 most recent readings. When a new reading comes, the last reading will need to be dropped from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ProcessStream():\n",
    "    past_readings = []\n",
    "    def step(self, s):\n",
    "        if len(self.past_readings) >= 24:\n",
    "            self.past_readings = self.past_readings[1:]\n",
    "        self.past_readings.append(s)\n",
    "        return(np.mean(self.past_readings))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 24.400000\n",
      "Average: 24.400000\n",
      "Average: 24.333333\n",
      "Average: 24.425000\n",
      "Average: 24.460000\n",
      "Average: 24.083333\n",
      "Average: 24.171429\n",
      "Average: 24.287500\n",
      "Average: 25.355556\n",
      "Average: 25.540000\n",
      "Average: 25.818182\n",
      "Average: 25.941667\n",
      "Average: 25.800000\n",
      "Average: 25.771429\n",
      "Average: 25.640000\n",
      "Average: 25.562500\n",
      "Average: 26.005882\n",
      "Average: 26.611111\n",
      "Average: 26.568421\n",
      "Average: 26.410000\n",
      "Average: 26.285714\n",
      "Average: 26.154545\n",
      "Average: 26.186957\n",
      "Average: 26.162500\n",
      "Average: 26.170833\n",
      "Average: 26.187500\n",
      "Average: 26.216667\n",
      "Average: 26.266667\n",
      "Average: 26.308333\n",
      "Average: 26.316667\n",
      "Average: 26.145833\n",
      "Average: 26.029167\n",
      "Average: 25.562500\n",
      "Average: 25.400000\n",
      "Average: 25.250000\n",
      "Average: 25.233333\n",
      "Average: 25.362500\n",
      "Average: 25.787500\n",
      "Average: 26.141667\n",
      "Average: 26.241667\n",
      "Average: 25.954167\n",
      "Average: 25.412500\n",
      "Average: 25.704167\n",
      "Average: 25.920833\n",
      "Average: 25.987500\n",
      "Average: 26.116667\n",
      "Average: 25.925000\n",
      "Average: 25.708333\n",
      "Average: 25.512500\n",
      "Average: 25.450000\n",
      "Average: 25.433333\n",
      "Average: 25.337500\n",
      "Average: 25.350000\n",
      "Average: 25.387500\n",
      "Average: 25.570833\n",
      "Average: 25.754167\n",
      "Average: 25.850000\n",
      "Average: 25.837500\n",
      "Average: 25.729167\n",
      "Average: 25.612500\n",
      "Average: 25.654167\n",
      "Average: 25.225000\n",
      "Average: 24.870833\n",
      "Average: 24.704167\n",
      "Average: 24.654167\n",
      "Average: 24.620833\n",
      "Average: 24.337500\n",
      "Average: 24.137500\n",
      "Average: 24.341667\n",
      "Average: 24.308333\n",
      "Average: 24.500000\n",
      "Average: 24.675000\n",
      "Average: 24.762500\n",
      "Average: 24.729167\n",
      "Average: 24.491667\n",
      "Average: 24.395833\n",
      "Average: 24.258333\n",
      "Average: 24.241667\n",
      "Average: 24.162500\n",
      "Average: 24.087500\n",
      "Average: 24.012500\n",
      "Average: 24.054167\n",
      "Average: 24.104167\n",
      "Average: 24.104167\n",
      "Average: 23.904167\n",
      "Average: 23.820833\n",
      "Average: 23.812500\n",
      "Average: 23.825000\n",
      "Average: 23.750000\n",
      "Average: 24.054167\n",
      "Average: 24.137500\n",
      "Average: 24.095833\n",
      "Average: 24.129167\n",
      "Average: 24.150000\n",
      "Average: 24.004167\n",
      "Average: 24.079167\n",
      "Average: 24.125000\n",
      "Average: 24.100000\n",
      "Average: 24.312500\n",
      "Average: 24.420833\n"
     ]
    }
   ],
   "source": [
    "t = temperature_sensor()\n",
    "stream_processor = ProcessStream()\n",
    "for i in range(100):\n",
    "    avg = stream_processor.step(next(t))\n",
    "    print(\"Average: %f\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average temperature from the beginning of the stream\n",
    "We cannot store all past records since the size of the stream is potentially infinite. But we can keep the sum and count in working storage and with this information compute the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessStream():\n",
    "    past_sum = 0\n",
    "    past_count = 0\n",
    "    def step(self, s):\n",
    "        self.past_sum += s\n",
    "        self.past_count += 1\n",
    "        return(self.past_sum / self.past_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 24.400000\n",
      "Average: 24.400000\n",
      "Average: 24.333333\n",
      "Average: 24.425000\n",
      "Average: 24.460000\n",
      "Average: 24.083333\n",
      "Average: 24.171429\n",
      "Average: 24.287500\n",
      "Average: 25.355556\n",
      "Average: 25.540000\n",
      "Average: 25.818182\n",
      "Average: 25.941667\n",
      "Average: 25.800000\n",
      "Average: 25.771429\n",
      "Average: 25.640000\n",
      "Average: 25.562500\n",
      "Average: 26.005882\n",
      "Average: 26.611111\n",
      "Average: 26.568421\n",
      "Average: 26.410000\n",
      "Average: 26.285714\n",
      "Average: 26.154545\n",
      "Average: 26.186957\n",
      "Average: 26.162500\n",
      "Average: 26.100000\n",
      "Average: 26.050000\n",
      "Average: 26.007407\n",
      "Average: 26.003571\n",
      "Average: 25.989655\n",
      "Average: 25.870000\n",
      "Average: 25.700000\n",
      "Average: 25.593750\n",
      "Average: 25.506061\n",
      "Average: 25.441176\n",
      "Average: 25.428571\n",
      "Average: 25.469444\n",
      "Average: 25.516216\n",
      "Average: 25.781579\n",
      "Average: 25.948718\n",
      "Average: 25.970000\n",
      "Average: 25.975610\n",
      "Average: 25.926190\n",
      "Average: 26.086047\n",
      "Average: 26.143182\n",
      "Average: 26.126667\n",
      "Average: 26.134783\n",
      "Average: 26.053191\n",
      "Average: 25.935417\n",
      "Average: 25.812245\n",
      "Average: 25.762000\n",
      "Average: 25.737255\n",
      "Average: 25.696154\n",
      "Average: 25.700000\n",
      "Average: 25.655556\n",
      "Average: 25.643636\n",
      "Average: 25.662500\n",
      "Average: 25.650877\n",
      "Average: 25.605172\n",
      "Average: 25.550847\n",
      "Average: 25.526667\n",
      "Average: 25.570492\n",
      "Average: 25.566129\n",
      "Average: 25.538095\n",
      "Average: 25.495313\n",
      "Average: 25.487692\n",
      "Average: 25.451515\n",
      "Average: 25.459701\n",
      "Average: 25.435294\n",
      "Average: 25.505797\n",
      "Average: 25.508571\n",
      "Average: 25.528169\n",
      "Average: 25.515278\n",
      "Average: 25.467123\n",
      "Average: 25.427027\n",
      "Average: 25.338667\n",
      "Average: 25.285526\n",
      "Average: 25.250649\n",
      "Average: 25.220513\n",
      "Average: 25.193671\n",
      "Average: 25.190000\n",
      "Average: 25.165432\n",
      "Average: 25.151220\n",
      "Average: 25.132530\n",
      "Average: 25.120238\n",
      "Average: 25.100000\n",
      "Average: 25.079070\n",
      "Average: 25.062069\n",
      "Average: 25.039773\n",
      "Average: 25.019101\n",
      "Average: 25.078889\n",
      "Average: 25.110989\n",
      "Average: 25.085870\n",
      "Average: 25.150538\n",
      "Average: 25.161702\n",
      "Average: 25.143158\n",
      "Average: 25.156250\n",
      "Average: 25.135052\n",
      "Average: 25.102041\n",
      "Average: 25.089899\n",
      "Average: 25.078000\n"
     ]
    }
   ],
   "source": [
    "t = temperature_sensor()\n",
    "stream_processor = ProcessStream()\n",
    "for i in range(100):\n",
    "    avg = stream_processor.step(next(t))\n",
    "    print(\"Average: %f\" % avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
