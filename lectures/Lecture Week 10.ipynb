{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Itemsets\n",
    "Let's work with the tweets set that we are using in the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "if not Path('../assignments/10000 tweets-NEW.json').exists():\n",
    "    print(\"Unzipping tweets\")\n",
    "    with zipfile.ZipFile('../assignments/cleaned-tweets.zip') as myzip:\n",
    "        myzip.extractall('../assignments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lecture, we will count frequencies of pair of words in the collection of tweets. The following code implements a Python generator that generates the list of words in each tweet after removing a pre-defined set of words that are known to be very frequent (the so-called *stop words*). We will use NLTK to split the tweets into words and remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def stream_tweets():\n",
    "    with open('../assignments/10000 tweets-NEW.json', encoding='iso8859-1') as jfile:\n",
    "        for line in jfile:\n",
    "            try:\n",
    "                next_tweet = json.loads(line)['body']\n",
    "                tweet_words = [w for w in next_tweet.split()\n",
    "                               if w.lower() not in stop_words] \n",
    "            except:\n",
    "                continue\n",
    "            yield tweet_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Register', '#Convergence2016', 'hear@ChelleMelbourne', 'talk', 'manage', 'change', 'digital', 'transformation', 'https://t.co/7pxwwDeaXm']\n",
      "['CONGRATULATIONS', 'Suzie', 'Walker', 'beautiful', 'little', 'man', 'FANTASTIC', 'commitment', 'hard', 'work.', 'You...', 'https://t.co/m4QLVq0BTr']\n",
      "['Wantirna,', 'VIC,', 'AU', '11:00', 'Temp', '19.8Â°C,', 'RH', '67pct,', 'Winds', 'NNW', '@', '0.0', 'km/h,', 'Rain', 'Today', '0', 'mm,', '1014.3', 'hpa', '&amp;', 'Steady.', '#vicweather']\n",
      "['much', 'see', 'Visit', 'Central', 'Australia', '\"We', 'kind', 'beaches', '#RedCentreNT!', 'The...', 'https://t.co/eRyP7eTk9X']\n",
      "[\"Friday's\", '3pm', 'Free', 'BBQ,', 'Bikini', 'Girls', '&amp;', 'Beverages', 'Meat', 'Raffles', 'around', 'Lunch', 'Time', 'Seafood', 'Raffle', '4pm...', 'https://t.co/etPRxJ2l7x']\n",
      "['Say', 'Hello', 'Gorgeous', 'Gingham', 'Dress!', 'Perfect', 'day', 'Play', 'Party.', 'Originally', '$50', '$40!...', 'https://t.co/ILI5uaCIHw']\n",
      "['Great', 'read', 'MBS', 'alumna', 'Leanda', 'Lee', '(MBA,', '1997)', '#mindfulness,', 'attention', '&amp;', 'balance', 'via', '@MacauDailyTimes', 'https://t.co/kPgPsFGbvX', '#MBSNow']\n",
      "['FOLLOWING', 'TAKES', 'PLACE', '11:00AM', '12:00PM.']\n",
      "['need', 'Forex', 'knowledge.', 'trade', 'â\\x80\\x93', 'need', 'watch', 'profits', 'coming.', 'https://t.co/LUMo3FOJZx']\n",
      "['Last', 'Dragon', '-', '30th', 'Anniversary', 'Blu-ray', 'Trailer', 'https://t.co/mooRbUHMZ6']\n",
      "['Great', 'article', 'benefits', 'mediation.', 'https://t.co/5Nu1ERH8Ch']\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for s in stream_tweets():\n",
    "    if counter > 10:\n",
    "        break\n",
    "    counter += 1\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-Priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the first pass of the A-Priori algorithm. It uses `Counter` from Python's `collections` library to count the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter()\n",
    "for tweet_words in stream_tweets():\n",
    "    counts.update(tweet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', 1575),\n",
       " ('-', 427),\n",
       " ('&amp;', 202),\n",
       " (\"I'm\", 180),\n",
       " ('via', 163),\n",
       " ('like', 160),\n",
       " ('need', 143),\n",
       " ('April', 139),\n",
       " ('one', 127),\n",
       " ('get', 127),\n",
       " ('time', 123),\n",
       " ('going', 113),\n",
       " ('people', 112),\n",
       " ('Clinton', 104),\n",
       " ('New', 103),\n",
       " ('new', 102),\n",
       " ('threat', 100),\n",
       " ('right', 98),\n",
       " ('good', 95),\n",
       " ('Hillary', 93)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above listed the 20 most frequent \"words\". The following code performs pass 2 of A-Priori using a threshold of 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "threshold = 30\n",
    "counts_pairs = dict()\n",
    "for tweet_words in stream_tweets():\n",
    "    for wi, wj in itertools.combinations(tweet_words, 2):\n",
    "        if counts[wi] < threshold or counts[wj] < threshold:\n",
    "            continue\n",
    "        if (wi, wj) not in counts_pairs:\n",
    "            counts_pairs[(wi, wj)] = 1\n",
    "        else:\n",
    "            counts_pairs[(wi, wj)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3554"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27306"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above shows that 3554 pairs were counted. Let's see how many pairs have a support over the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for k in counts_pairs:\n",
    "    if counts_pairs[k] >= threshold:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found 194 pairs of frequent words. Let's print some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('April', 'Fools') 39\n",
      "('RT', '-') 81\n",
      "('RT', '&amp;') 79\n",
      "('RT', 'people') 37\n",
      "('RT', 'time') 41\n",
      "('RT', 'like') 38\n",
      "('RT', 'April') 31\n",
      "('RT', 'Hillary') 59\n",
      "('RT', 'one') 54\n",
      "('-', '-') 70\n",
      "('RT', 'activist') 47\n",
      "('RT', \"I'm\") 68\n",
      "('RT', 'love') 35\n",
      "('liked', '@YouTube') 43\n",
      "('liked', 'video') 43\n",
      "('@YouTube', 'video') 43\n",
      "('RT', 'going') 69\n",
      "('RT', 'threat') 51\n",
      "('RT', '#iHeartAwards') 58\n",
      "('RT', '#5SOSFam') 51\n",
      "('RT', '#BestFanArmy') 55\n",
      "('#iHeartAwards', '#5SOSFam') 40\n",
      "('#iHeartAwards', '#BestFanArmy') 43\n",
      "('#5SOSFam', '#BestFanArmy') 47\n",
      "('RT', '@Tha5SOSFamily:') 43\n",
      "('@Tha5SOSFamily:', '#iHeartAwards') 41\n",
      "('@Tha5SOSFamily:', '#BestFanArmy') 37\n",
      "('@Tha5SOSFamily:', '#5SOSFam') 38\n",
      "('#BestFanArmy', '#5SOSFam') 36\n",
      "('RT', 'via') 52\n",
      "('RT', 'need') 85\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for k in counts_pairs:\n",
    "    if counts_pairs[k] >= threshold:\n",
    "        print(k, counts_pairs[k])\n",
    "        c+=1\n",
    "        if c > threshold:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCY\n",
    "The following code performs pass 1 of the PCY algorithm. We will use a hash with 10000 buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbuckets = 100000\n",
    "def my_hash(i,j):\n",
    "    return hash((i,j)) % nbuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "buckets = np.zeros(nbuckets)\n",
    "\n",
    "counts = Counter()\n",
    "for tweet_words in stream_tweets():\n",
    "    counts.update(tweet_words)\n",
    "    for i, j in itertools.combinations(tweet_words, 2):\n",
    "        buckets[my_hash(i,j)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following code performs pass 2 of the PCY algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_pairs = dict()\n",
    "for tweet_words in stream_tweets():\n",
    "    for i, j in itertools.combinations(tweet_words, 2):\n",
    "        if counts[i] < threshold or counts[j] < threshold:\n",
    "            continue\n",
    "        if buckets[my_hash(i,j)] < threshold:\n",
    "            continue\n",
    "#        print(\"Counting pair\", i, j)\n",
    "        if (i,j) not in counts_pairs:\n",
    "            counts_pairs[(i,j)] = 1\n",
    "        else:\n",
    "            counts_pairs[(i,j)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many pairs were counted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tries several values of number of buckets and prints the numbers of pairs that are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with 5000 buckets\n",
      "Number of pairs counted: 3554\n",
      "Trying with 10000 buckets\n",
      "Number of pairs counted: 2417\n",
      "Trying with 20000 buckets\n",
      "Number of pairs counted: 394\n",
      "Trying with 50000 buckets\n",
      "Number of pairs counted: 241\n",
      "Trying with 100000 buckets\n",
      "Number of pairs counted: 212\n",
      "Trying with 200000 buckets\n",
      "Number of pairs counted: 203\n",
      "Trying with 500000 buckets\n",
      "Number of pairs counted: 196\n"
     ]
    }
   ],
   "source": [
    "def my_hash(i, j, nbuckets):\n",
    "    return hash((i,j)) % nbuckets\n",
    "\n",
    "plotdata = []\n",
    "for nbuckets in (5000, 10000, 20000, 50000, 100000, 200000, 500000):\n",
    "    print(\"Trying with %i buckets\" % nbuckets)\n",
    "    # Pass 1\n",
    "    buckets = np.zeros(nbuckets)\n",
    "    counts = Counter()\n",
    "    for tweet_words in stream_tweets():\n",
    "        counts.update(tweet_words)\n",
    "        for i, j in itertools.combinations(tweet_words, 2):\n",
    "            buckets[my_hash(i, j, nbuckets)] += 1\n",
    "            \n",
    "    # Pass 2\n",
    "    counts_pairs = dict()\n",
    "    for tweet_words in stream_tweets():\n",
    "        for i, j in itertools.combinations(tweet_words, 2):\n",
    "            if counts[i] < threshold or counts[j] < threshold:\n",
    "                continue\n",
    "            if buckets[my_hash(i, j, nbuckets)] < threshold:\n",
    "                continue\n",
    "    #        print(\"Counting pair\", i, j)\n",
    "            if (i,j) not in counts_pairs:\n",
    "                counts_pairs[(i,j)] = 1\n",
    "            else:\n",
    "                counts_pairs[(i,j)] += 1 \n",
    "    print(\"Number of pairs counted:\", len(counts_pairs))\n",
    "    plotdata.append(len(counts_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
